"""
ì²˜ë¦¬ëœ ì²­í¬ ë°ì´í„°ë¡œ ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
ë©”ëª¨ë¦¬ ëª¨ë“œë¡œ ì‘ë™ (JSON íŒŒì¼ì—ì„œ ë¡œë“œ)
"""

import sys
import json
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))

from dotenv import load_dotenv
import os
from src.services.embedding_service import EmbeddingService
from src.services.vector_store import VectorStore

def load_chunks_from_json(processed_dir: str = "data/processed"):
    """JSON íŒŒì¼ì—ì„œ ì²­í¬ ë¡œë“œ"""
    processed_path = Path(processed_dir)
    chunks_by_collection = {}

    print("ğŸ“‚ Loading chunks from JSON files...")

    for json_file in processed_path.glob("*_chunks.json"):
        with open(json_file, 'r', encoding='utf-8') as f:
            chunks = json.load(f)

        # ë¬¸ì„œ IDì—ì„œ ì»¬ë ‰ì…˜ ì´ë¦„ ì¶”ì¶œ
        doc_id = json_file.stem.replace('_chunks', '')

        # ì»¬ë ‰ì…˜ ì´ë¦„ ìƒì„± (ì˜ˆ: crm_account_ko_v1_0 -> crm_account_ko)
        parts = doc_id.split('_')
        if len(parts) >= 4:
            collection_name = f"{parts[0]}_{parts[1]}_{parts[2]}"
        else:
            collection_name = doc_id

        if collection_name not in chunks_by_collection:
            chunks_by_collection[collection_name] = []

        chunks_by_collection[collection_name].extend(chunks)
        print(f"  âœ“ {json_file.name}: {len(chunks)} chunks -> {collection_name}")

    return chunks_by_collection

def test_search(query: str, language: str = "auto"):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""

    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")

    if not api_key:
        print("âŒ OPENAI_API_KEY not found in .env")
        return

    # ì–¸ì–´ ìë™ ê°ì§€
    if language == "auto":
        from langdetect import detect
        try:
            detected = detect(query)
            language = "korean" if detected == "ko" else "english"
        except:
            language = "korean"  # ê¸°ë³¸ê°’

    print(f"\n{'='*60}")
    print(f"ğŸ” Search Test")
    print(f"{'='*60}")
    print(f"Query: {query}")
    print(f"Language: {language} (auto-detected)")
    print(f"{'='*60}\n")

    # ì„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    print("1ï¸âƒ£  Initializing embedding service...")
    embedding_service = EmbeddingService(
        model_name="openai/text-embedding-3-large",
        api_key=api_key,
        cache_enabled=True
    )

    # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (ë©”ëª¨ë¦¬ ëª¨ë“œ)
    print("2ï¸âƒ£  Initializing vector store (in-memory)...")
    vector_store = VectorStore(use_memory=True)

    # ì²­í¬ ë¡œë“œ
    print("\n3ï¸âƒ£  Loading chunks from JSON files...")
    chunks_by_collection = load_chunks_from_json()

    total_chunks = sum(len(chunks) for chunks in chunks_by_collection.values())
    print(f"\nâœ… Loaded {total_chunks} chunks from {len(chunks_by_collection)} collections")

    # ì»¬ë ‰ì…˜ ìƒì„± ë° ë°ì´í„° ì¶”ê°€
    print("\n4ï¸âƒ£  Creating collections and adding data...")
    for collection_name, chunks in chunks_by_collection.items():
        # ì»¬ë ‰ì…˜ ìƒì„±
        vector_store.create_collection(
            collection_name=collection_name,
            vector_size=3072,
            recreate=True
        )

        # ì²­í¬ì— ì„ë² ë”© ì¶”ê°€ (ìºì‹œì—ì„œ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±)
        print(f"\n   Processing {collection_name}...")
        chunk_texts = [chunk['text'] for chunk in chunks]
        embeddings = embedding_service.embed_batch(chunk_texts, show_progress=False)

        # ë²¡í„° ìŠ¤í† ì–´ìš© ë°ì´í„° ì¤€ë¹„
        vector_chunks = []
        for chunk, embedding in zip(chunks, embeddings):
            vector_chunk = {
                "chunk_id": chunk["chunk_id"],
                "text": chunk["text"],
                "embedding": embedding,
                "metadata": chunk["metadata"]
            }
            vector_chunks.append(vector_chunk)

        # ë°ì´í„° ì¶”ê°€
        vector_store.add_documents(
            collection_name=collection_name,
            chunks=vector_chunks,
            show_progress=False
        )
        print(f"   âœ“ Added {len(vector_chunks)} chunks to {collection_name}")

    # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    print(f"\n5ï¸âƒ£  Generating query embedding...")
    query_embedding = embedding_service.embed_text(query)

    # ì–¸ì–´ì— ë”°ë¥¸ ì»¬ë ‰ì…˜ í•„í„°
    lang_code = "ko" if language == "korean" else "en"

    # ëª¨ë“  ê´€ë ¨ ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰
    print(f"\n6ï¸âƒ£  Searching in collections (language: {lang_code})...")
    all_results = []

    for collection_name in chunks_by_collection.keys():
        if f"_{lang_code}" in collection_name:
            results = vector_store.search(
                collection_name=collection_name,
                query_vector=query_embedding,
                top_k=3,
                score_threshold=0.5
            )

            for result in results:
                result.metadata["collection"] = collection_name
                all_results.append(result)

            if results:
                print(f"   âœ“ {collection_name}: {len(results)} results")

    # ì ìˆ˜ ìˆœ ì •ë ¬
    all_results.sort(key=lambda x: x.score, reverse=True)
    top_results = all_results[:5]

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ¯ Search Results (Top {len(top_results)})")
    print(f"{'='*60}\n")

    if not top_results:
        print("âŒ No results found")
        return

    for i, result in enumerate(top_results, 1):
        print(f"[{i}] Score: {result.score:.4f}")
        print(f"    Collection: {result.metadata.get('collection', 'N/A')}")
        print(f"    Chunk ID: {result.chunk_id}")
        print(f"    Document: {result.metadata.get('document_id', 'N/A')}")
        print(f"    Type: {result.metadata.get('type', 'N/A')}")
        print(f"    Text Preview: {result.text[:200]}...")
        print()

    print(f"{'='*60}")
    print("âœ… Search test completed!")

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
        test_search(query)
    else:
        print("Usage: python test_search.py <query>")
        print("\nExample queries:")
        print("  python test_search.py ê±°ë˜ì„  ë“±ë¡ ë°©ë²•")
        print("  python test_search.py ë¯¸íŒ…ë©”ëª¨ ì‘ì„±")
        print("  python test_search.py ì£¼ë¬¸ ìŠ¹ì¸")
