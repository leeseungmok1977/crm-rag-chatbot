"""
ì„ë² ë”© ì„œë¹„ìŠ¤ ëª¨ë“ˆ
- í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
- ìºì‹± ê¸°ëŠ¥
- ë‹¤ì–‘í•œ ì„ë² ë”© ëª¨ë¸ ì§€ì›
"""

import hashlib
import json
from typing import List, Dict, Optional, Literal
from pathlib import Path
import time

import numpy as np
from openai import OpenAI
from tqdm import tqdm

# Optional: sentence_transformers for local models
try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    SentenceTransformer = None


class EmbeddingCache:
    """ì„ë² ë”© ìºì‹œ (ë¡œì»¬ íŒŒì¼ ê¸°ë°˜)"""

    def __init__(self, cache_dir: str = "data/embeddings"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def _get_cache_key(self, text: str, model: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        content = f"{model}:{text}"
        return hashlib.md5(content.encode()).hexdigest()

    def get(self, text: str, model: str) -> Optional[List[float]]:
        """ìºì‹œì—ì„œ ì„ë² ë”© ì¡°íšŒ"""
        cache_key = self._get_cache_key(text, model)
        cache_file = self.cache_dir / f"{cache_key}.json"

        if cache_file.exists():
            with open(cache_file, 'r') as f:
                data = json.load(f)
                return data["embedding"]
        return None

    def set(self, text: str, model: str, embedding: List[float]):
        """ìºì‹œì— ì„ë² ë”© ì €ì¥"""
        cache_key = self._get_cache_key(text, model)
        cache_file = self.cache_dir / f"{cache_key}.json"

        with open(cache_file, 'w') as f:
            json.dump({
                "text": text[:100],  # ì²˜ìŒ 100ìë§Œ ì €ì¥ (ì°¸ê³ ìš©)
                "model": model,
                "embedding": embedding,
                "timestamp": time.time()
            }, f)

    def clear(self):
        """ìºì‹œ ì „ì²´ ì‚­ì œ"""
        for cache_file in self.cache_dir.glob("*.json"):
            cache_file.unlink()


class EmbeddingService:
    """
    ì„ë² ë”© ì„œë¹„ìŠ¤

    ì§€ì› ëª¨ë¸:
    - OpenAI: text-embedding-3-large, text-embedding-3-small
    - SentenceTransformers: ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸
    """

    def __init__(
        self,
        model_name: str = "openai/text-embedding-3-large",
        api_key: Optional[str] = None,
        cache_enabled: bool = True,
        cache_dir: str = "data/embeddings"
    ):
        """
        Args:
            model_name: ëª¨ë¸ ì´ë¦„ (provider/model í˜•ì‹)
            api_key: OpenAI API í‚¤ (OpenAI ëª¨ë¸ ì‚¬ìš© ì‹œ)
            cache_enabled: ìºì‹± í™œì„±í™” ì—¬ë¶€
            cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬
        """
        self.model_name = model_name
        self.provider, self.model = self._parse_model_name(model_name)

        # ìºì‹œ ì„¤ì •
        self.cache_enabled = cache_enabled
        if cache_enabled:
            self.cache = EmbeddingCache(cache_dir)
        else:
            self.cache = None

        # ëª¨ë¸ ì´ˆê¸°í™”
        if self.provider == "openai":
            if not api_key:
                raise ValueError("OpenAI API key is required")
            self.client = OpenAI(api_key=api_key)
            self.dimension = self._get_openai_dimension(self.model)
        elif self.provider == "sentence-transformers":
            if not SENTENCE_TRANSFORMERS_AVAILABLE:
                raise ImportError(
                    "sentence-transformers is not installed. "
                    "Install it with: pip install sentence-transformers"
                )
            self.model_st = SentenceTransformer(self.model)
            self.dimension = self.model_st.get_sentence_embedding_dimension()
        else:
            raise ValueError(f"Unknown provider: {self.provider}")

        print(f"âœ… Embedding service initialized: {model_name} (dim={self.dimension})")

    def _parse_model_name(self, model_name: str) -> tuple[str, str]:
        """ëª¨ë¸ ì´ë¦„ íŒŒì‹±"""
        if "/" in model_name:
            provider, model = model_name.split("/", 1)
        else:
            # ê¸°ë³¸ provider
            provider = "sentence-transformers"
            model = model_name
        return provider, model

    def _get_openai_dimension(self, model: str) -> int:
        """OpenAI ëª¨ë¸ì˜ ì°¨ì› ë°˜í™˜"""
        dimensions = {
            "text-embedding-3-large": 3072,
            "text-embedding-3-small": 1536,
            "text-embedding-ada-002": 1536,
        }
        return dimensions.get(model, 1536)

    def embed_text(self, text: str) -> List[float]:
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ ì„ë² ë”©

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸

        Returns:
            ì„ë² ë”© ë²¡í„°
        """
        # ìºì‹œ í™•ì¸
        if self.cache_enabled:
            cached = self.cache.get(text, self.model_name)
            if cached is not None:
                return cached

        # ì„ë² ë”© ìƒì„±
        if self.provider == "openai":
            embedding = self._embed_openai([text])[0]
        elif self.provider == "sentence-transformers":
            embedding = self._embed_sentence_transformer([text])[0]
        else:
            raise ValueError(f"Unknown provider: {self.provider}")

        # ìºì‹œ ì €ì¥
        if self.cache_enabled:
            self.cache.set(text, self.model_name, embedding)

        return embedding

    def embed_batch(
        self,
        texts: List[str],
        batch_size: int = 100,
        show_progress: bool = True
    ) -> List[List[float]]:
        """
        ë°°ì¹˜ í…ìŠ¤íŠ¸ ì„ë² ë”©

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸°
            show_progress: ì§„í–‰ë¥  í‘œì‹œ

        Returns:
            ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        embeddings = []
        uncached_texts = []
        uncached_indices = []

        # ìºì‹œ í™•ì¸
        if self.cache_enabled:
            for i, text in enumerate(texts):
                cached = self.cache.get(text, self.model_name)
                if cached is not None:
                    embeddings.append(cached)
                else:
                    embeddings.append(None)
                    uncached_texts.append(text)
                    uncached_indices.append(i)
        else:
            uncached_texts = texts
            uncached_indices = list(range(len(texts)))
            embeddings = [None] * len(texts)

        # ìºì‹œë˜ì§€ ì•Šì€ í…ìŠ¤íŠ¸ ì„ë² ë”©
        if uncached_texts:
            print(f"ğŸ“Š Embedding {len(uncached_texts)} texts (cached: {len(texts) - len(uncached_texts)})")

            batches = [
                uncached_texts[i:i + batch_size]
                for i in range(0, len(uncached_texts), batch_size)
            ]

            batch_embeddings = []
            iterator = tqdm(batches, desc="Embedding") if show_progress else batches

            for batch in iterator:
                if self.provider == "openai":
                    batch_emb = self._embed_openai(batch)
                elif self.provider == "sentence-transformers":
                    batch_emb = self._embed_sentence_transformer(batch)
                else:
                    raise ValueError(f"Unknown provider: {self.provider}")

                batch_embeddings.extend(batch_emb)

                # Rate limiting for OpenAI
                if self.provider == "openai":
                    time.sleep(0.1)

            # ìºì‹œ ì €ì¥ ë° ê²°ê³¼ ì—…ë°ì´íŠ¸
            for idx, text, emb in zip(uncached_indices, uncached_texts, batch_embeddings):
                if self.cache_enabled:
                    self.cache.set(text, self.model_name, emb)
                embeddings[idx] = emb

        return embeddings

    def _embed_openai(self, texts: List[str]) -> List[List[float]]:
        """OpenAI APIë¡œ ì„ë² ë”©"""
        try:
            response = self.client.embeddings.create(
                model=self.model,
                input=texts
            )
            embeddings = [data.embedding for data in response.data]
            return embeddings
        except Exception as e:
            print(f"âŒ OpenAI embedding error: {e}")
            raise

    def _embed_sentence_transformer(self, texts: List[str]) -> List[List[float]]:
        """SentenceTransformerë¡œ ì„ë² ë”©"""
        embeddings = self.model_st.encode(
            texts,
            convert_to_numpy=True,
            show_progress_bar=False
        )
        return embeddings.tolist()

    def compute_similarity(
        self,
        embedding1: List[float],
        embedding2: List[float]
    ) -> float:
        """
        ë‘ ì„ë² ë”©ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°

        Returns:
            ìœ ì‚¬ë„ (0~1)
        """
        vec1 = np.array(embedding1)
        vec2 = np.array(embedding2)

        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)

        if norm1 == 0 or norm2 == 0:
            return 0.0

        similarity = dot_product / (norm1 * norm2)
        return float(similarity)

    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            "model_name": self.model_name,
            "provider": self.provider,
            "model": self.model,
            "dimension": self.dimension,
            "cache_enabled": self.cache_enabled
        }


class MultilingualEmbeddingService:
    """
    ë‹¤êµ­ì–´ ì„ë² ë”© ì„œë¹„ìŠ¤

    ì–¸ì–´ë³„ë¡œ ìµœì í™”ëœ ëª¨ë¸ ì‚¬ìš©
    """

    def __init__(
        self,
        default_model: str = "openai/text-embedding-3-large",
        language_models: Optional[Dict[str, str]] = None,
        api_key: Optional[str] = None
    ):
        """
        Args:
            default_model: ê¸°ë³¸ ëª¨ë¸
            language_models: ì–¸ì–´ë³„ ëª¨ë¸ ë§¤í•‘ (ì˜ˆ: {"korean": "model1", "english": "model2"})
            api_key: OpenAI API í‚¤
        """
        self.default_model = default_model
        self.language_models = language_models or {}
        self.api_key = api_key

        # ì–¸ì–´ë³„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.services: Dict[str, EmbeddingService] = {}

        # ê¸°ë³¸ ì„œë¹„ìŠ¤
        self.services["default"] = EmbeddingService(
            model_name=default_model,
            api_key=api_key
        )

        # ì–¸ì–´ë³„ ì„œë¹„ìŠ¤
        for lang, model in self.language_models.items():
            self.services[lang] = EmbeddingService(
                model_name=model,
                api_key=api_key
            )

    def embed_text(self, text: str, language: str = "auto") -> List[float]:
        """
        í…ìŠ¤íŠ¸ ì„ë² ë”© (ì–¸ì–´ ìë™ ì„ íƒ)

        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            language: ì–¸ì–´ ("auto"ë©´ ìë™ ê°ì§€)

        Returns:
            ì„ë² ë”© ë²¡í„°
        """
        if language == "auto":
            language = self._detect_language(text)

        service = self.services.get(language, self.services["default"])
        return service.embed_text(text)

    def embed_batch(
        self,
        texts: List[str],
        languages: Optional[List[str]] = None,
        batch_size: int = 100
    ) -> List[List[float]]:
        """
        ë°°ì¹˜ í…ìŠ¤íŠ¸ ì„ë² ë”©

        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            languages: ê° í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ (Noneì´ë©´ ìë™ ê°ì§€)
            batch_size: ë°°ì¹˜ í¬ê¸°

        Returns:
            ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        """
        if languages is None:
            languages = [self._detect_language(text) for text in texts]

        # ì–¸ì–´ë³„ë¡œ ê·¸ë£¹í™”
        groups: Dict[str, List[tuple[int, str]]] = {}
        for i, (text, lang) in enumerate(zip(texts, languages)):
            if lang not in groups:
                groups[lang] = []
            groups[lang].append((i, text))

        # ì–¸ì–´ë³„ë¡œ ì„ë² ë”©
        embeddings = [None] * len(texts)
        for lang, items in groups.items():
            indices, lang_texts = zip(*items)
            service = self.services.get(lang, self.services["default"])
            lang_embeddings = service.embed_batch(lang_texts, batch_size)

            for idx, emb in zip(indices, lang_embeddings):
                embeddings[idx] = emb

        return embeddings

    def _detect_language(self, text: str) -> str:
        """ê°„ë‹¨í•œ ì–¸ì–´ ê°ì§€"""
        from langdetect import detect

        try:
            lang_code = detect(text)
            lang_map = {
                "ko": "korean",
                "en": "english",
                "ja": "japanese",
                "zh-cn": "chinese",
            }
            return lang_map.get(lang_code, "default")
        except:
            return "default"


# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
def create_embedding_service(
    provider: Literal["openai", "local"] = "openai",
    api_key: Optional[str] = None
) -> EmbeddingService:
    """
    ê°„í¸í•œ ì„ë² ë”© ì„œë¹„ìŠ¤ ìƒì„±

    Args:
        provider: "openai" ë˜ëŠ” "local"
        api_key: OpenAI API í‚¤

    Returns:
        EmbeddingService ì¸ìŠ¤í„´ìŠ¤
    """
    if provider == "openai":
        if not api_key:
            raise ValueError("OpenAI API key is required")
        return EmbeddingService(
            model_name="openai/text-embedding-3-large",
            api_key=api_key
        )
    elif provider == "local":
        # ë¡œì»¬ ëª¨ë¸ (ë¬´ë£Œ)
        return EmbeddingService(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
    else:
        raise ValueError(f"Unknown provider: {provider}")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import os
    from dotenv import load_dotenv

    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")

    # OpenAI ì„ë² ë”© í…ŒìŠ¤íŠ¸
    print("=== OpenAI Embedding Test ===")
    service = EmbeddingService(
        model_name="openai/text-embedding-3-large",
        api_key=api_key
    )

    text1 = "ê±°ë˜ì„  ë“±ë¡ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”"
    text2 = "How to register a new account"
    text3 = "CRM ì‹œìŠ¤í…œ ì‚¬ìš©ë²•"

    # ë‹¨ì¼ ì„ë² ë”©
    emb1 = service.embed_text(text1)
    print(f"Text: {text1}")
    print(f"Embedding dim: {len(emb1)}")
    print(f"First 5 values: {emb1[:5]}")

    # ë°°ì¹˜ ì„ë² ë”©
    texts = [text1, text2, text3]
    embeddings = service.embed_batch(texts)
    print(f"\nBatch embedding: {len(embeddings)} texts")

    # ìœ ì‚¬ë„ ê³„ì‚°
    similarity = service.compute_similarity(embeddings[0], embeddings[2])
    print(f"\nSimilarity between '{text1}' and '{text3}': {similarity:.4f}")

    # ë¡œì»¬ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("\n=== Local Model Test ===")
    local_service = EmbeddingService(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    emb_local = local_service.embed_text(text1)
    print(f"Local embedding dim: {len(emb_local)}")
